import requests
import pandas as pd
import os
import time
import random
from dotenv import load_dotenv

# Load environment variables from .env
load_dotenv()

API_KEY = os.getenv("OPENROUTER_API_KEY")

if not API_KEY:
    raise ValueError("‚ùå API Key not found. Please set OPENROUTER_API_KEY in .env")
else:
    print("‚úÖ API Key loaded:", API_KEY[:8], "‚Ä¶")



API_URL = "https://openrouter.ai/api/v1/chat/completions"

if not API_KEY:
    raise ValueError("API Key not found.")

models = [
    "deepseek/deepseek-chat-v3.1:free",
    "google/gemini-2.0-flash-exp:free",
    "meta-llama/llama-3.3-70b-instruct:free"
]

sheet_id = "1yLfUbxmEBlaXFxb2Etd51lIQ0YdPtbBLmVAYzdQYoTs"
gid = "0"
google_sheet_url = (
    f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?"
    f"tqx=out:csv&gid={gid}"
)

question_column_name = "Question (Bengali)"


PROMPT = (
    "‡¶Ü‡¶™‡¶®‡¶ø ‡¶è‡¶ï‡¶ú‡¶® ‡¶Ö‡¶≠‡¶ø‡¶ú‡ßç‡¶û ‡¶Æ‡ßÅ‡¶∏‡¶≤‡¶ø‡¶Æ ‡¶Ü‡¶á‡¶® ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û‡•§ "
    "‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶ú ‡¶π‡¶≤‡ßã ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞‡¶ï‡¶æ‡¶∞‡ßÄ‡¶∞ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®‡ßá‡¶∞ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶ï‡ßã‡¶∞‡¶Ü‡¶®, ‡¶π‡¶æ‡¶¶‡ßÄ‡¶∏, ‡¶è‡¶¨‡¶Ç ‡¶á‡¶∏‡¶≤‡¶æ‡¶Æ‡ßá‡¶∞ ‡¶Ü‡¶≤‡ßã‡¶ï‡ßá ‡¶™‡ßç‡¶∞‡¶¶‡¶æ‡¶® ‡¶ï‡¶∞‡¶æ‡•§ "
    "‡¶â‡¶§‡ßç‡¶§‡¶∞‡¶ó‡ßÅ‡¶≤‡¶ø ‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡¶ø‡¶™‡ßç‡¶§, ‡¶∏‡ßç‡¶™‡¶∑‡ßç‡¶ü ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶†‡¶ø‡¶ï ‡¶π‡¶ì‡¶Ø‡¶º‡¶æ ‡¶â‡¶ö‡¶ø‡¶§, ‡¶∏‡¶∞‡ßç‡¶¨‡ßã‡¶ö‡ßç‡¶ö ‡ß™‚Äì‡ß´ ‡¶≤‡¶æ‡¶á‡¶®‡ßá‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶∏‡ßÄ‡¶Æ‡¶æ‡¶¨‡¶¶‡ßç‡¶ß ‡¶∞‡¶æ‡¶ñ‡ßÅ‡¶®‡•§ "
    "‡¶Ö‡¶®‡ßÅ‡¶Æ‡¶æ‡¶® ‡¶¨‡¶æ ‡¶¨‡ßç‡¶Ø‡¶ï‡ßç‡¶§‡¶ø‡¶ó‡¶§ ‡¶Æ‡¶§‡¶æ‡¶Æ‡¶§ ‡¶¶‡ßá‡¶ì‡¶Ø‡¶º‡¶æ ‡¶•‡ßá‡¶ï‡ßá ‡¶¨‡¶ø‡¶∞‡¶§ ‡¶•‡¶æ‡¶ï‡ßÅ‡¶®‡•§ "
    "‡¶™‡ßç‡¶∞‡¶§‡ßç‡¶Ø‡ßá‡¶ï‡¶ü‡¶ø ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶Ö‡¶¨‡¶∂‡ßç‡¶Ø‡¶á ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶Ø‡¶º ‡¶¶‡¶ø‡¶¨‡ßá‡¶®‡•§\n\n"
    "‡¶™‡ßç‡¶∞‡¶§‡ßç‡¶Ø‡ßá‡¶ï ‡¶â‡¶§‡ßç‡¶§‡¶∞‡ßá‡¶∞ ‡¶´‡¶∞‡¶Æ‡ßç‡¶Ø‡¶æ‡¶ü:\n"
    "Answer:\n<‡¶∏‡¶Ç‡¶ï‡ßç‡¶∑‡¶ø‡¶™‡ßç‡¶§ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶è‡¶ñ‡¶æ‡¶®‡ßá>\n\n"
    "References:\n<‡¶™‡ßç‡¶∞‡¶æ‡¶∏‡¶ô‡ßç‡¶ó‡¶ø‡¶ï ‡¶Ü‡¶Ø‡¶º‡¶æ‡¶§ ‡¶¨‡¶æ ‡¶π‡¶æ‡¶¶‡ßÄ‡¶∏‡ßá‡¶∞ ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞ ‡¶è‡¶ñ‡¶æ‡¶®‡ßá>\n\n"
    "‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®: {}"
)

def query_model(question, model, retries=5, delay=5, timeout=60):
    """
    Query a model with retries and capped exponential backoff for 429 errors.
    """
    for attempt in range(1, retries + 1):
        try:
            headers = {
                "Authorization": f"Bearer {API_KEY}",
                "Content-Type": "application/json",
                "HTTP-Referer": "http://localhost",
                "X-Title": "Free QA Experiment"
            }

            payload = {
                "model": model,
                "messages": [
                    {"role": "system", "content": PROMPT},
                    {"role": "user", "content": question}
                ]
            }

            response = requests.post(API_URL, headers=headers, json=payload, timeout=timeout)
            
            if response.status_code == 429:
                wait_time = min(delay * (2 ** attempt), 60)
                print(f"‚ö†Ô∏è Rate limit hit for {model}, retrying in {wait_time:.0f}s...")
                time.sleep(wait_time)
                continue
            elif response.status_code >= 400:
                response.raise_for_status()
            
            resp_json = response.json()
            return resp_json["choices"][0]["message"]["content"]

        except requests.exceptions.RequestException as e:
            print(f"‚ö†Ô∏è Attempt {attempt} failed for {model}: {e}")
            time.sleep(min(delay * (2 ** attempt), 60))
        except Exception as e:
            print(f"‚ö†Ô∏è Unexpected error for {model}: {e}")
            return "Failed"
    
    return "Failed"

def process_question_for_all_models(question):
    """Query all models sequentially for a single question"""
    results = {"question": question}
    print(f"\n‚ùì Processing question: {question[:50]}...")

    for model in models:
        answer = query_model(question, model)
        results[model] = answer
        print(f" ¬† ‚Üí Finished {model}: {'Success' if answer != 'Failed' else 'Failed'}")
        time.sleep(5 + random.uniform(0, 3))

    return results


try:
    print(f"üì• Loading data from Google Sheet: {google_sheet_url}")
    df = pd.read_csv(google_sheet_url)
    initial = 1
    final = 2
    # Use the specified slice of the DataFrame
    df = df.iloc[initial:final]

    if question_column_name not in df.columns:
        raise ValueError(f"Column '{question_column_name}' not found in Google Sheet.")
except Exception as e:
    raise RuntimeError(f"Failed to load Google Sheet: {e}")

all_results = []
batch_size = 1
sleep_between_batches = 60

for i in range(0, len(df), batch_size):
    batch_df = df.iloc[i:i + batch_size]
    print(f"\nüì¶ Processing batch {i // batch_size + 1} ({len(batch_df)} questions)...")

    for idx, row in batch_df.iterrows():
        question = row[question_column_name]
        batch_results = process_question_for_all_models(question)
        print(batch_results)
        all_results.append(batch_results)
        pd.DataFrame(all_results).to_csv("answers_free_partial.csv", index=False, encoding="utf-8-sig")
    
    print(f"‚è∏ Pausing {sleep_between_batches}s to respect free-tier limits...")
    time.sleep(sleep_between_batches)

results_df = pd.DataFrame(all_results)
results_df.to_csv("answers_free.csv", index=False, encoding="utf-8-sig")
print("\n‚úÖ Finished! All answers saved in 'answers_free.csv'.")